#!/usr/bin/env python3
import math
import torch
from torch import nn
import torch.nn.functional as F

class transformer_model(nn.Module):
	def __init__(self, k, heads=4, mask=False):
		super().__init__()
		assert k % heads == 0
		self.k, self.heads = k, heads
		self.tokeys    = nn.Linear(k, k, bias=False)
		self.toqueries = nn.Linear(k, k, bias=False)
		self.tovalues  = nn.Linear(k, k, bias=False)
		self.unifyheads = nn.Linear(k, k)
		self.linear_embedding = torch.nn.Linear(4,k)

	def forward(self, x,in_hitnr):
		x = x[:in_hitnr]
		x = self.linear_embedding(x)	
		t, k = x.size()
		h = self.heads
		queries = self.toqueries(x)
		keys    = self.tokeys(x)
		values  = self.tovalues(x)
		s = k // h
		keys    = keys.view(t, h, s)
		queries = queries.view(t, h, s)
		values  = values.view(t, h, s)
		# - fold heads into the batch dimension
		keys = keys.transpose(1, 2).contiguous().view(h, t, s)
		queries = queries.transpose(1, 2).contiguous().view(h, t, s)
		values = values.transpose(1, 2).contiguous().view(h, t, s)
		# Get dot product of queries and keys, and scale
		dot = torch.bmm(queries, keys.transpose(1, 2))	
		dot = dot / (s ** (1/2))
		dot = F.softmax(dot,dim=2)
		out = torch.bmm(dot, values).view(h, t, s) 
		out = out.transpose(1,2).contiguous().view(t, s * h)
		out = self.unifyheads(out)
		#use cosine similarity
		L2_dist = torch.cosine_similarity(out[None] , out[:,None],dim=-1)		
		L2_dist = 0.5*(L2_dist+1)
		upper_tri_mask = torch.triu(torch.ones((out.shape[0],out.shape[0])),diagonal=1).bool() ##out should have shape: batchsize,hitnr,hitnr
		return L2_dist[upper_tri_mask]

























